{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import pyswarms as ps\n",
    "import math\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_20.csv\")\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "y = (y != 0).astype(int)\n",
    "\n",
    "undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "X_res, y_res = undersampler.fit_resample(X, y)\n",
    "\n",
    "df_res = pd.DataFrame(X_res, columns=X.columns)  \n",
    "df_res['target'] = y_res\n",
    "num_class = len(np.unique(y_res))\n",
    "\n",
    "desired_size_per_class = 1000\n",
    "\n",
    "data = pd.concat([\n",
    "    df_class.sample(n=desired_size_per_class, random_state=42)\n",
    "    for _, df_class in df_res.groupby('target')\n",
    "])\n",
    "\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Initialize patterns and correlations for training data\n",
    "pattern_list = []\n",
    "train_correlations = np.zeros(len(X_train))\n",
    "\n",
    "# Convert data to numpy arrays once (avoid repeated conversion)\n",
    "X_train_array = X_train.values\n",
    "X_test_array = X_test.values\n",
    "\n",
    "# Pre-compute standardized training data\n",
    "X_train_means = X_train_array.mean(axis=1, keepdims=True)\n",
    "X_train_stds = X_train_array.std(axis=1, keepdims=True)\n",
    "X_train_stds[X_train_stds == 0] = 1\n",
    "X_train_standardized = (X_train_array - X_train_means) / X_train_stds\n",
    "\n",
    "# Pre-compute standardized test data\n",
    "X_test_means = X_test_array.mean(axis=1, keepdims=True)\n",
    "X_test_stds = X_test_array.std(axis=1, keepdims=True)\n",
    "X_test_stds[X_test_stds == 0] = 1\n",
    "X_test_standardized = (X_test_array - X_test_means) / X_test_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized objective function with subsampling\n",
    "def objective_for_optimization(params, existing_pattern_list, existing_correlations, sample_indices):\n",
    "    corr_threshold = params[0]\n",
    "    pattern_index_float = params[1]\n",
    "    \n",
    "    # Convert index to integer and bound it\n",
    "    max_index = len(existing_pattern_list)\n",
    "    pattern_index = min(max_index, math.floor(pattern_index_float * (max_index + 1)))\n",
    "    \n",
    "    # Extract pattern parameters\n",
    "    new_pattern = params[2:]\n",
    "    \n",
    "    # Use only the sampled indices\n",
    "    sampled_X = X_train_standardized[sample_indices]\n",
    "    sampled_y = y_train.iloc[sample_indices]\n",
    "    sampled_correlations = existing_correlations[sample_indices]\n",
    "    \n",
    "    # Make a copy of correlations (avoid modifying original)\n",
    "    temp_correlations = sampled_correlations.copy()\n",
    "    \n",
    "    # Standardize pattern (once per evaluation)\n",
    "    pattern_mean = np.mean(new_pattern)\n",
    "    pattern_std_dev = np.std(new_pattern) or 1\n",
    "    pattern_std = (new_pattern - pattern_mean) / pattern_std_dev\n",
    "    \n",
    "    # Calculate new pattern correlation efficiently for sampled data\n",
    "    pattern_correlations = np.sum(sampled_X * pattern_std, axis=1) / len(pattern_std)\n",
    "    # Apply ReLU - set negative correlations to zero\n",
    "    pattern_correlations = np.maximum(0, pattern_correlations)\n",
    "    \n",
    "    # Handle existing pattern replacement\n",
    "    if pattern_index < len(existing_pattern_list):\n",
    "        old_pattern = existing_pattern_list[pattern_index]\n",
    "        old_pattern_mean = np.mean(old_pattern)\n",
    "        old_pattern_std_dev = np.std(old_pattern) or 1\n",
    "        old_pattern_std = (old_pattern - old_pattern_mean) / old_pattern_std_dev\n",
    "        old_correlations = np.sum(sampled_X * old_pattern_std, axis=1) / len(old_pattern_std)\n",
    "        # Apply ReLU to old correlations\n",
    "        old_correlations = np.maximum(0, old_correlations)\n",
    "        temp_correlations -= old_correlations\n",
    "    \n",
    "    # Add new pattern correlation\n",
    "    temp_correlations += pattern_correlations\n",
    "    \n",
    "    # Fast evaluation\n",
    "    preds = (temp_correlations > corr_threshold).astype(int)\n",
    "    pos_count = np.sum(preds)\n",
    "    if pos_count == 0 or pos_count == len(preds):\n",
    "        return -1\n",
    "    \n",
    "    # Only calculate AUC if predictions are valid\n",
    "    return roc_auc_score(sampled_y, temp_correlations)\n",
    "\n",
    "# Simplified objective for pyswarms (avoiding unnecessary return values)\n",
    "def pyswarms_objective(particles):\n",
    "    n_particles = particles.shape[0]\n",
    "    j = np.zeros(n_particles)\n",
    "    \n",
    "    # Sample 50% of training data for stochastic approximation\n",
    "    sample_size = len(X_train) // 2\n",
    "    sample_indices = np.random.choice(len(X_train), sample_size, replace=False)\n",
    "    \n",
    "    for i in range(n_particles):\n",
    "        auc = objective_for_optimization(particles[i], pattern_list, train_correlations, sample_indices)\n",
    "        j[i] = -auc\n",
    "    \n",
    "    return j\n",
    "\n",
    "# Faster correlation calculation for a dataset\n",
    "def calculate_correlations(X_standardized, patterns):\n",
    "    correlations = np.zeros(len(X_standardized))\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        pattern_mean = np.mean(pattern)\n",
    "        pattern_std_dev = np.std(pattern) or 1\n",
    "        pattern_std = (pattern - pattern_mean) / pattern_std_dev\n",
    "        pattern_correlations = np.sum(X_standardized * pattern_std, axis=1) / len(pattern_std)\n",
    "        # Apply ReLU - set negative correlations to zero\n",
    "        pattern_correlations = np.maximum(0, pattern_correlations)\n",
    "        correlations += pattern_correlations\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "# Optimization parameters \n",
    "n_particles = 300\n",
    "max_iterations = 100\n",
    "\n",
    "# PSO options - tuned for faster convergence\n",
    "options = {\n",
    "    'c1': 0.7,  # Higher cognitive parameter for faster convergence \n",
    "    'c2': 0.5,  # Social parameter\n",
    "    'w': 2,   # The higher the inertia, the more exploration\n",
    "    'k': 2,     # Fewer neighbors to check\n",
    "    'p': 2      # Minkowski p-norm\n",
    "}\n",
    "\n",
    "# Configure bounds -\n",
    "def create_bounds():\n",
    "    max_bound = np.ones(22)  # All parameters normalized to 0-1 range\n",
    "    min_bound = np.zeros(22)\n",
    "    return (min_bound, max_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Creating new pattern at index 4, Train AUC: 0.8459, Test AUC: 0.8540\n",
      "Iteration 2, Creating new pattern at index 5, Train AUC: 0.8506, Test AUC: 0.8564\n",
      "Iteration 3, Updating pattern at index 0, Train AUC: 0.8540, Test AUC: 0.8515\n",
      "Iteration 4, Updating pattern at index 0, Train AUC: 0.8565, Test AUC: 0.8561\n",
      "Iteration 5, Creating new pattern at index 6, Train AUC: 0.8565, Test AUC: 0.8561\n",
      "Iteration 6, Creating new pattern at index 7, Train AUC: 0.8565, Test AUC: 0.8561\n",
      "Iteration 7, Creating new pattern at index 8, Train AUC: 0.8568, Test AUC: 0.8550\n",
      "Iteration 8, Updating pattern at index 8, Train AUC: 0.8569, Test AUC: 0.8585\n",
      "Iteration 9, Updating pattern at index 3, Train AUC: 0.8628, Test AUC: 0.8664\n",
      "Iteration 10, Creating new pattern at index 9, Train AUC: 0.8639, Test AUC: 0.8651\n",
      "Iteration 11, Updating pattern at index 0, Train AUC: 0.8686, Test AUC: 0.8732\n",
      "Iteration 12, Updating pattern at index 6, Train AUC: 0.8682, Test AUC: 0.8731\n",
      "Training AUC decreased from 0.8686 to 0.8682. Stopping.\n",
      "\n",
      "--- Final Evaluation ---\n",
      "Test AUC: 0.8731\n",
      "Number of patterns: 10\n",
      "Best threshold: 0.1459\n"
     ]
    }
   ],
   "source": [
    "# Run optimization until AUC stops improving\n",
    "previous_train_auc = 0\n",
    "current_train_auc = 0\n",
    "iteration = 0\n",
    "best_test_auc = 0\n",
    "best_threshold = 0\n",
    "\n",
    "while True:\n",
    "    bounds = create_bounds()\n",
    "    \n",
    "    optimizer = ps.single.GlobalBestPSO(\n",
    "        n_particles=n_particles,\n",
    "        dimensions=22, \n",
    "        options=options,\n",
    "        bounds=bounds\n",
    "    )\n",
    "    \n",
    "    # Perform optimization\n",
    "    best_cost, best_pos = optimizer.optimize(\n",
    "        pyswarms_objective, \n",
    "        iters=max_iterations,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Extract parameters\n",
    "    corr_threshold = best_pos[0]\n",
    "    pattern_index_float = best_pos[1]\n",
    "    new_pattern = best_pos[2:]\n",
    "    \n",
    "    # Convert index to integer\n",
    "    max_index = len(pattern_list)\n",
    "    pattern_index = min(max_index, math.floor(pattern_index_float * (max_index + 1)))\n",
    "    \n",
    "    # Action type\n",
    "    action = \"Updating\" if pattern_index < len(pattern_list) else \"Creating new\"\n",
    "    \n",
    "    # Standardize pattern\n",
    "    pattern_mean = np.mean(new_pattern)\n",
    "    pattern_std_dev = np.std(new_pattern) or 1\n",
    "    pattern_std = (new_pattern - pattern_mean) / pattern_std_dev\n",
    "    \n",
    "    # Calculate correlation on full training set\n",
    "    pattern_correlations = np.sum(X_train_standardized * pattern_std, axis=1) / len(pattern_std)\n",
    "    # Apply ReLU - set negative correlations to zero\n",
    "    pattern_correlations = np.maximum(0, pattern_correlations)\n",
    "    \n",
    "    # Handle pattern update/creation\n",
    "    if pattern_index < len(pattern_list):\n",
    "        old_pattern = pattern_list[pattern_index]\n",
    "        old_pattern_mean = np.mean(old_pattern)\n",
    "        old_pattern_std_dev = np.std(old_pattern) or 1\n",
    "        old_pattern_std = (old_pattern - old_pattern_mean) / old_pattern_std_dev\n",
    "        old_correlations = np.sum(X_train_standardized * old_pattern_std, axis=1) / len(old_pattern_std)\n",
    "        # Apply ReLU to old correlations\n",
    "        old_correlations = np.maximum(0, old_correlations)\n",
    "        train_correlations -= old_correlations\n",
    "        pattern_list[pattern_index] = new_pattern\n",
    "    else:\n",
    "        pattern_list.append(new_pattern)\n",
    "    \n",
    "    # Update correlations\n",
    "    train_correlations += pattern_correlations\n",
    "    \n",
    "    # Calculate test performance\n",
    "    test_correlations = calculate_correlations(X_test_standardized, pattern_list)\n",
    "    \n",
    "    # Evaluate performance on full datasets\n",
    "    previous_train_auc = current_train_auc\n",
    "    current_train_auc = roc_auc_score(y_train, train_correlations)\n",
    "    test_auc = roc_auc_score(y_test, test_correlations)\n",
    "    \n",
    "    # Track best performance\n",
    "    if test_auc > best_test_auc:\n",
    "        best_test_auc = test_auc\n",
    "        best_threshold = corr_threshold\n",
    "    \n",
    "    print(f\"Iteration {iteration+1}, {action} pattern at index {pattern_index}, Train AUC: {current_train_auc:.4f}, Test AUC: {test_auc:.4f}\")\n",
    "    \n",
    "    # Increment iteration counter\n",
    "    iteration += 1\n",
    "    \n",
    "    # Check if AUC decreased (break condition)\n",
    "    if iteration > 1 and current_train_auc < previous_train_auc:\n",
    "        print(f\"Training AUC decreased from {previous_train_auc:.4f} to {current_train_auc:.4f}. Stopping.\")\n",
    "        break\n",
    "\n",
    "# Final evaluation (using full test set)\n",
    "final_test_correlations = calculate_correlations(X_test_standardized, pattern_list)\n",
    "final_test_preds = (final_test_correlations > best_threshold).astype(int)\n",
    "final_test_auc = roc_auc_score(y_test, final_test_correlations)\n",
    "\n",
    "print(\"\\n--- Final Evaluation ---\")\n",
    "print(f\"Test AUC: {final_test_auc:.4f}\")\n",
    "print(f\"Number of patterns: {len(pattern_list)}\")\n",
    "print(f\"Best threshold: {best_threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
